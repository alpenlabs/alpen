//! Generic cache utility for what we're inserting into the database.

use std::{cell::RefCell, cmp::PartialEq, hash::Hash, marker::PhantomData, num::NonZeroUsize};

use ahash::RandomState;
use cache_advisor::CacheAdvisor;
use concurrent_map::{CasFailure, ConcurrentMap};
use kanal::{bounded_async, AsyncReceiver};
use strata_db::{DbError, DbResult};
use tracing::*;

use crate::exec::DbRecv;

/// Describes a cache entry that may be occupied, reserved for pending database read, or returned an
/// error from a database read.
#[derive(Debug, Clone, PartialEq)]
pub enum Entry<T: Clone> {
    /// Authentic database entry.
    Ready(T),

    /// A database fetch is happening in the background and it will be updated.
    Pending(Receiver<DbResult<T>>),
}

// Do not use outside this module.
//
// A wrapper around a async kanal receiver that implements PartialEq so we can
// do cas ops. We don't actually CAS between SlotState::Pending and
// SlotState::Pending, so this is fine.
#[derive(Debug, Clone)]
pub struct Receiver<T>(AsyncReceiver<T>);

impl<T> AsRef<AsyncReceiver<T>> for Receiver<T> {
    fn as_ref(&self) -> &AsyncReceiver<T> {
        &self.0
    }
}

impl<T> PartialEq for Receiver<T> {
    fn eq(&self, _other: &Self) -> bool {
        // this is only so we can
        false
    }
}
impl<T> Eq for Receiver<T> {}

impl<T: Clone> Entry<T> {
    /// Tries to read a value from the slot, asynchronously.
    pub async fn get_async(&self) -> DbResult<T> {
        match self {
            Self::Ready(v) => Ok(v.clone()),
            Self::Pending(ch) => {
                // When we see this log get triggered and but feels like the corresponding fetch is
                // hanging for this read then it means that this code wasn't implemented
                // correctly.
                // TODO figure out how to test this
                trace!("waiting for database fetch to complete");
                match ch.0.recv().await {
                    Ok(v) => v,
                    Err(_e) => Err(DbError::WorkerFailedStrangely),
                }
            }
        }
    }

    /// Tries to read a value from the slot, blockingly.
    pub fn get_blocking(&self) -> DbResult<T> {
        match self {
            Self::Ready(v) => Ok(v.clone()),
            Self::Pending(ch) => {
                // When we see this log get triggered and but feels like the corresponding fetch is
                // hanging for this read then it means that this code wasn't implemented
                // correctly.
                // TODO figure out how to test this
                trace!("waiting for database fetch to complete");
                match ch.0.as_sync().recv() {
                    Ok(v) => v,
                    Err(_e) => Err(DbError::WorkerFailedStrangely),
                }
            }
        }
    }
}

/// Wrapper around a LRU cache that handles cache reservations and asynchronously waiting for
/// database operations in the background without keeping a global lock on the cache.
#[derive(Debug, Clone)]
pub struct CacheTable<K, V>
where
    K: Hash,
    V: 'static + CacheTableValue + PartialEq,
{
    table: ConcurrentMap<u64, Entry<V>>,
    advisor: RefCell<CacheAdvisor>,
    hasher: RandomState,
    _k: PhantomData<K>,
}

pub trait CacheTableValue: Clone + Send + Sync {}
impl<V> CacheTableValue for V where V: Clone + Send + Sync {}

impl<K, V> CacheTable<K, V>
where
    K: Hash,
    V: 'static + CacheTableValue + PartialEq,
{
    /// Creates a new cache with some maximum capacity.
    ///
    /// This measures entries by *count* not their (serialized?) size, so ideally entries should
    /// consume similar amounts of memory to helps us best reason about real cache capacity.
    pub fn new(size: NonZeroUsize) -> Self {
        Self {
            table: ConcurrentMap::new(),
            advisor: CacheAdvisor::new(size.get(), 20).into(),
            hasher: RandomState::new(),
            _k: PhantomData,
        }
    }

    /// Gets the number of elements in the cache.
    pub fn len(&self) -> usize {
        self.table.len()
    }

    /// Removes the entry for a particular cache entry.
    pub fn purge(&self, k: &K) {
        self.table.remove(&self.hasher.hash_one(k));
    }

    /// Inserts an entry into the table, dropping the previous value.
    pub fn insert(&self, k: K, v: V) {
        let hash = self.hasher.hash_one(&k);
        self.table.insert(hash, Entry::Ready(v));
        self.record_access_and_evict(hash);
    }

    fn record_access_and_evict(&self, hash: u64) {
        for (hash, _cost) in self.advisor.borrow_mut().accessed_reuse_buffer(hash, 1) {
            self.table.remove(hash);
        }
    }

    /// Returns a clone of an entry from the cache or possibly invoking some function returning a
    /// `oneshot` channel that will return the value from the underlying database.
    ///
    /// This is meant to be used with the `_chan` functions generated by the db ops macro in the
    /// `exec` module.
    pub async fn get_or_fetch(&self, k: &K, fetch_fn: impl Fn() -> DbRecv<V>) -> DbResult<V> {
        let hash = self.hasher.hash_one(k);
        self.record_access_and_evict(hash);

        let (tx, rx) = bounded_async(1);
        // mmmmmm atomic cas ops
        if let Err(CasFailure { actual, .. }) =
            self.table
                .cas(hash, None, Some(Entry::Pending(Receiver(rx))))
        {
            return actual.expect("should be Some").get_async().await;
        }

        // Start the task and get the recv handle.
        let res_fut = fetch_fn();

        let res = match res_fut.await {
            Ok(res) => {
                if let Err(ref e) = res {
                    error!(?e, "failed to make database fetch");
                }
                res
            }
            Err(_) => {
                error!("database fetch aborted");
                return Err(DbError::WorkerFailedStrangely);
            }
        };

        // Update the cache entry if we got a value.
        if let Ok(v) = res.clone() {
            self.table.insert(hash, Entry::Ready(v));
        }

        // Update any waiting readers.
        if tx.send(res.clone()).await.is_err() {
            warn!("failed to notify waiting cache readers");
        }

        res
    }

    /// Returns a clone of an entry from the cache or invokes some function to load it from
    /// the underlying database.
    pub fn get_or_fetch_blocking(&self, k: &K, fetch_fn: impl Fn() -> DbResult<V>) -> DbResult<V> {
        let hash = self.hasher.hash_one(k);
        self.record_access_and_evict(hash);

        let (tx, rx) = bounded_async(1);
        // mmmmmm atomic cas ops
        if let Err(CasFailure { actual, .. }) =
            self.table
                .cas(hash, None, Some(Entry::Pending(Receiver(rx))))
        {
            return actual.expect("should be Some").get_blocking();
        }

        let res = fetch_fn();

        if let Err(ref e) = res {
            error!(?e, "failed to make database fetch");
        };

        // Update the cache entry if we got a value.
        if let Ok(v) = res.clone() {
            self.table.insert(hash, Entry::Ready(v));
        }

        // Update any waiting readers.
        if tx.as_sync().send(res.clone()).is_err() {
            warn!("failed to notify waiting cache readers");
        }

        res
    }
}

#[cfg(test)]
mod tests {
    use strata_db::DbError;

    use super::CacheTable;

    #[tokio::test]
    async fn test_basic_async() {
        let cache = CacheTable::<u64, u64>::new(3.try_into().unwrap());

        let res = cache
            .get_or_fetch(&42, || {
                let (tx, rx) = tokio::sync::oneshot::channel();
                tx.send(Ok(10)).expect("test: send init value");
                rx
            })
            .await
            .expect("test: cache gof");
        assert_eq!(res, 10);

        let res = cache
            .get_or_fetch(&42, || {
                let (tx, rx) = tokio::sync::oneshot::channel();
                tx.send(Err(DbError::Busy)).expect("test: send init value");
                rx
            })
            .await
            .expect("test: load gof");
        assert_eq!(res, 10);

        cache.insert(42, 12);
        let res = cache
            .get_or_fetch(&42, || {
                let (tx, rx) = tokio::sync::oneshot::channel();
                tx.send(Err(DbError::Busy)).expect("test: send init value");
                rx
            })
            .await
            .expect("test: load gof");
        assert_eq!(res, 12);

        let len = cache.len();
        assert_eq!(len, 1);
        cache.purge(&42);
        let len = cache.len();
        assert_eq!(len, 0);
    }

    #[test]
    fn test_basic_blocking() {
        let cache = CacheTable::<u64, u64>::new(3.try_into().unwrap());

        let res = cache
            .get_or_fetch_blocking(&42, || Ok(10))
            .expect("test: cache gof");
        assert_eq!(res, 10);

        let res = cache
            .get_or_fetch_blocking(&42, || Err(DbError::Busy))
            .expect("test: load gof");
        assert_eq!(res, 10);

        cache.insert(42, 12);
        let res = cache
            .get_or_fetch_blocking(&42, || Err(DbError::Busy))
            .expect("test: load gof");
        assert_eq!(res, 12);

        let len = cache.len();
        assert_eq!(len, 1);
        cache.purge(&42);
        let len = cache.len();
        assert_eq!(len, 0);
    }
}
